---
output: html_document
editor_options: 
  chunk_output_type: console
---
# Data Cleaning

## EMA 

### Loneliness States 

Below is code that was run before data could be shared with outside parties. It is included below for transparency and will generate the data files loaded in the chunks that follow. 

```{r, eval = F}
sc_soc <- sc_df %>%
  select(
    SID, Date = Date_main, session:HourBlock, matches("lonely")
    , ss_disclose, ss_understood, ss_rejected, iso_when = `sh-iso_when`
    ) %>%
  pivot_longer(
    cols = c(-(SID:HourBlock), -iso_when)
    , values_to = "value"
    , names_to = "old"
    , values_drop_na = T
  ) %>%
  mutate(
    # reverse score
    value = ifelse(old == "ss_rejected" | grepl("lonely", old), 6 - value, value)
    , iso_when = 5 - iso_when
    ) %>%
  separate(old, c("domain", "item"), sep = "_") 

pomp <- function(x, mini = 1, maxi = 5) (x - mini)/(maxi - mini)*100

sc_soc <- sc_soc %>% 
  filter(!grepl("iso", domain)) %>%
  group_by(SID, Date, StartDate, Day, Hour, HourBlock, session, domain, item) %>%
  summarize(value = mean(value, na.rm = T)) %>% 
  group_by(SID, Date, StartDate, Day, Hour, HourBlock, session, domain) %>% 
  summarize(value = mean(value, na.rm = T)) %>% 
  ungroup() %>%
  pivot_wider(
    names_from = "domain"
    , values_from = "value"
    ) %>%
  full_join(
    sc_soc %>%
    filter(!grepl("iso", domain)) %>%
      pivot_wider(
        names_from = c("domain", "item")
        , values_from = "value"
        , values_fn = mean
        )
  ) %>% 
  mutate_at(vars(matches("lonely")), pomp) %>%
  mutate_at(vars(matches("^ss")), ~pomp(., 0 , 6))
```

### Cognitive States 

```{r, eval = F}
pomp_obs <- function(x) (x - min(x, na.rm = T))/(max(x, na.rm = T)-min(x, na.rm = T))*100
sc_cog <- sc_df %>% 
  select(
    SID, Date = Date_main, session:HourBlock
         , nback_score, vpa_score, dsm_score
         , nback_medianRTc, vpa_medianRTc, dsm_medianRTc
         ) %>%
  mutate(
    nback_medianRTc = ifelse(nback_medianRTc > 5000 | nback_medianRTc == 0, NA, nback_medianRTc)
    , vpa_medianRTc = ifelse(vpa_medianRTc > 7500 | vpa_medianRTc == 0, NA, vpa_medianRTc)
    , dsm_medianRTc = ifelse(dsm_medianRTc > 5000 | vpa_medianRTc == 0, NA, dsm_medianRTc)
  ) %>%
  mutate_at(vars(nback_score, vpa_score, dsm_score), pomp_obs) %>%
  mutate_at(vars(nback_medianRTc, vpa_medianRTc, dsm_medianRTc), lst(pomp = pomp_obs)) %>%
  rowwise() %>%
  mutate(
    cog_comp = mean(c_across(nback_score:dsm_score), na.rm = T)
    , cog_medianRTc = mean(c_across(nback_medianRTc_pomp:dsm_medianRTc_pomp), na.rm = T)
    ) %>%
  ungroup() 

sc_soccog <- sc_soc %>%
  inner_join(
    sc_cog 
    ) %>%
  select(-StartDate, -HourBlock)
save(sc_soccog, file = sprintf("../loneliness-cog-melsm/lonely-cog-ema-%s.RData", Sys.Date()))
write_csv(sc_soccog, file = sprintf("../loneliness-cog-melsm/lonely-cog-ema-%s.csv", Sys.Date()))
```

### Load and Reshape 

Now we load in the data and do a few small rescaling steps to aid model convergence. 

```{r}
load("01-data/lonely-cog-ema-2025-04-21.RData")
sc_all <- sc_soccog
subs <- sc_soccog %>% 
  select(SID) %>%
  group_by(SID) %>%
  filter(n() >= 50) %>% 
  distinct() %>% pull(SID)

sc_soccog <- sc_soccog  %>% 
  mutate_at(vars(lonely, ss, iso_when), ~(.)/10) %>%
  mutate(nback_score = ifelse(nback_score == 0, NA, nback_score)) %>% 
  filter(SID %in% subs)
```

The data above include both scale score composites and individual items, where applicable for estimating reliability. 

#### Within-Person Centering 

Next, we need to create and center some variables. First we'll create: 

- a beep variable (how many EMAs did a person do [practice effects])
- a decimal time variable (time of day) 
- person means of social interaction recency and quality 

Second, we'll center: 
- beeps (person median centered)
- decimal time (person mean centered)
- momentary loneliness (person mean centered)
- momentary social interaction recency (person mean centered)
- momentary social interaction quality (person mean centered)
- average social interaction recency (grand mean centered)
- average social interaction quality (grand mean centered)

```{r}
sc_soccog <- sc_soccog %>% 
  arrange(SID, Date) %>%
  group_by(SID) %>%
  mutate(
    beep = 1:n()
    , beep_wpc = beep - median(beep)
    , dec_time = hour(Date) + minute(Date)/60 + second(Date)/60/60
    , dec_time_c = dec_time - 12
    , lonely_wpc = center(lonely)
    , ss_qual_wpc = center(ss)
    , ss_quant_wpc = center(iso_when)
    ) %>%
  ungroup() %>%
  left_join(
    sc_soccog %>% 
      select(SID:session, ss, iso_when) %>% 
      group_by(SID) %>%
      summarize(
        ss_qual = mean(ss, na.rm = T)
        , ss_quant = mean(iso_when, na.rm = T)
        ) %>%
      ungroup() %>%
      mutate(
        ss_qual_gmc = center(ss_qual)
        , ss_quant_gmc = center(ss_quant)
      )
  )
sc_soccog 
```

### Loneliness Instability 

Next, we need to estimate loneliness instability as a person-level variable for RQ1. To adjust for unequal intervals, we follow procedures by Jahng et al. (2008). We then POMP score loneliness based on the observed estimates to allow for relative comparisons (and keep effect size interpretation consistent across variables). 

```{r}
mssd_fun <- function(x){
  # time corrected mssd adapted from Jahng et al. (2008)
  sd <- diff(x$lonely, lag = 1, na.rm = T)^2 # ssd
  td <- as.numeric(diff(x$Date, lag = 1, na.rm = T, units = "hours")) # t - t-1
  mtd <- median(td, na.rm = T) # median delta t
  den <- (sum(td < 18) - 1) # n - 1
  res <- (mtd/den)*sum(sd/td, na.rm = T)
  return(res)
}

sc_soccog <- sc_soccog %>% 
  group_by(SID) %>% 
  nest() %>%
  ungroup() %>%
  mutate(lonely_mssd = pomp_obs(sqrt(map_dbl(data, mssd_fun)))/10) %>%
  unnest(data) 

sc_soccog %>%
  select(SID, lonely_mssd) %>% 
  distinct() %>%
  ggplot(aes(x = lonely_mssd)) + 
  geom_density(fill = "#9AA0F9", alpha = .75) + 
  annotate("segment", arrow = arrow(type = "closed", length=unit(2, "mm")), size = 1, x = 4.8, xend = 0, y = -.02, yend = -.02) + 
  annotate("text", label = "Low Instability", x = 0, y = -.05, fontface = 2, hjust = 0) + 
  annotate("segment", arrow = arrow(type = "closed", length=unit(2, "mm")), size = 1, x = 5.2, xend = 10, y = -.02, yend = -.02) + 
  annotate("text", label = "High Instability", x = 10, y = -.05, fontface = 2, hjust = 1) + 
  # scale_x_continuous(limits = c(0, 10)) +
  labs(
    title = "Individual Differences in\nLoneliness Instability"
    , y = ""
    , x = "Loneliness Instability"
    ) + 
  my_theme() +
  theme(
    # axis.text = element_blank()
    , axis.ticks = element_blank()
    , panel.grid = element_blank()
    , panel.background = element_rect(color = "black", linewidth = 1.2)
    )
ggsave(file = "~/Downloads/instability.png", width = 3, height = 3)
```

## Baseline  

Next, we need to wrangle the baseline files

```{r}
load(file = "01-data/lonely-cog-baeline-2025-05-08.RData")

bl_df
```

### Scale Scores and Recoding 

```{r}
# race 
bl_demo <- bl_df %>%
  select(SID, matches("demo_ethnicity_[1-5]")) %>%
  rowwise() %>%
  mutate(
    race = sum(c_across(demo_ethnicity_1:demo_ethnicity_5), na.rm = T)
    , race = ifelse(race > 1, "Mixed Race", NA)
    , demo_ethnicity_1 = if_else(demo_ethnicity_1 == 1, "American Indian or Alaska Native", NA)
    , demo_ethnicity_2 = if_else(demo_ethnicity_2 == 1, "Asian", NA)
    , demo_ethnicity_3 = if_else(demo_ethnicity_3 == 1, "African American or Black", NA)
    , demo_ethnicity_4 = if_else(demo_ethnicity_4 == 1, "Native Hawaiian or Pacific Islander", NA)
    , demo_ethnicity_5 = if_else(demo_ethnicity_5 == 1, "European / White", NA)
  ) %>%
  pivot_longer(
    cols = matches("demo_ethnicity")
    , names_to = "name"
    , values_to = "value"
    , values_drop_na = T
  ) %>%
  mutate(race = if_else(is.na(race), value, race)) %>%
  select(SID, race) %>%
  # all other demo
  inner_join(
    bl_df %>%
      mutate(
        # gender
        demo_gender = ifelse(demo_gender > 1, 2, demo_gender)
        , gender_text = mapvalues(demo_gender, 0:2, c("Male", "Female", "Other"))
        
        # relationship status
        , relstat = mapvalues(demo_relationship, 1:7, c(1, 0, 0, 0, 2, 2, 2))
        , relstat_text = mapvalues(relstat, 0:2, c("Married/Partnered", "Single", "Separated/Divorced/Widowed"))
        , relstat_single = ifelse(relstat == 1, 1, 0)
        , relstat_sep = ifelse(relstat == 2, 1, 0)
        , relstat_part = ifelse(relstat == 0, 1, 0)
        
        # ethnicity
        , demo_hispanic = ifelse(demo_hispanic > 1, NA, demo_hispanic)
        , hispanic_text = mapvalues(demo_hispanic, 0:1, c("Not Hispanic or Latino", "Hispanic or Latino"))
        
        # education
        , edu_years = as.numeric(mapvalues(demo_education, c(0:8, 10), c(7, 10, 12, 14, 14, 16, 18, 21, NA, NA)))
        
        # age
        , demo_age = ifelse(demo_age == 1979, 45, demo_age)
        , age_c = (demo_age - 60)/10
        
        # income
        , demo_income = as.numeric(str_remove_all(demo_income, "\\$"))
        , income_log = log(demo_income)
        , income_log = ifelse(is.infinite(income_log), 0, income_log)
        ) %>%
      rename(gender = demo_gender, hispanic = demo_hispanic, age = demo_age, income = demo_income) %>%
      select(-matches("demo_ethnicity_\\d"), -matches("sh-loneliness"), -matches("BFI_"))
  ) %>%
  distinct() %>%
  inner_join(
    # loneliness
    bl_df %>% 
      select(SID, matches("loneliness")) %>%
      pivot_longer(
        cols = matches("loneliness")
        , names_to = "item"
        , values_to = "loneliness"
      ) %>%
      left_join(
        bl_cb %>% select(item = Item, Reverse)
      ) %>%
      mutate(loneliness = ifelse(Reverse == -1, 5 - loneliness, loneliness)) %>%
      group_by(SID) %>%
      summarize(loneliness = mean(loneliness, na.rm = T)) %>%
      ungroup() %>%
      mutate(loneliness = pomp(loneliness, mini = 1 , maxi = 4)/10)
  ) %>%
  inner_join(
    # loneliness
    bl_df %>% 
      select(SID, matches("BFI_N_[5-8]")) %>%
      pivot_longer(
        cols = -SID
        , names_to = "item"
        , values_to = "dep"
      ) %>%
      left_join(
        bl_cb %>% select(item = Item, Reverse)
      ) %>%
      mutate(dep = ifelse(Reverse == -1, 6 - dep, dep)) %>%
      group_by(SID) %>%
      summarize(dep = mean(dep, na.rm = T)) %>%
      ungroup() %>%
      mutate(dep = pomp(dep, mini = 1 , maxi = 5)/10)
  ) %>%
  left_join(
    bl_df %>% 
      select(SID, Matching_Shapes_and_Numbers:Vocabulary) %>%
      # mutate(pomp_obs(Matching_Shapes_and_Numbers))
      mutate_at(vars(-SID), as.numeric) %>%
      mutate_at(vars(-SID), pomp_obs) %>%
      pivot_longer(
        cols = -SID
        , names_to = "var"
        , values_to = "bl_cog"
        , values_drop_na = T
      ) %>%
      group_by(SID) %>%
      summarize(bl_cog = mean(bl_cog, na.rm = T)) %>%
      ungroup()
  ) %>%
  mutate(SID = as.numeric(SID))

bl_demo_trim <- bl_demo  %>%
  filter(SID %in% subs) %>%
      mutate(
        loneliness_gmc = center(loneliness)
        , gender_gmc = center(gender)
        , relstat_single_gmc = center(relstat_single)
        , relstat_sep_gmc = center(relstat_sep)
        , edu_years_gmc = center(edu_years)/10
        , income_log_gmc = income_log - median(income_log, na.rm = T)
        , dep_gmc = center(dep)
        )
  
bl_demo_trim %>%
  select(SID, loneliness_gmc, dep_gmc, gender_gmc, age_c, edu_years_gmc, income_log_gmc)
```

## Combine and Reshape 

Now we bring together all the variables and wrangle them for use in a standard modeling function that differentiates across research questions. 

```{r}
nested_models <- sc_soccog %>%
# outcome reshape 
  select(
    SID:session, SID:session, interrupt, beep_wpc, dec_time_c
    , cog_comp, cog_medianRTc, matches("nback"), matches("dsm"), matches("vpa"), -matches("pomp")
    ) %>%
  pivot_longer(
    cols = c(-(SID:dec_time_c))
    , names_to = "outcome"
    , values_to = "contemp"
  ) %>%
  group_by(SID, outcome) %>%
  mutate(prosp = lead(contemp)) %>%
  ungroup() %>%
  pivot_longer(
    cols = c(contemp, prosp)
    , names_to = "outcome_time"
    , values_to = "cog_value"
  ) %>%
  filter(!(grepl("medianRT", outcome) & cog_value == 0)) %>%
  full_join(
    # state loneliness and moderators
    sc_soccog %>%
      select(
        SID:session, interrupt, beep_wpc, dec_time_c
        , lonely_mssd, lonely_wpc
        , ss_qual_gmc, ss_quant_gmc
        , ss_qual_wpc, ss_quant_wpc, 
        ) %>%
      full_join(
        bl_demo_trim %>%
          select(SID, age_c, loneliness_gmc)
      ) %>%
      pivot_longer(
        cols = c(-(SID:lonely_wpc))
        , names_to = "moder"
        , values_to = "mod_value_c"
      ) %>%
      full_join(
        sc_soccog %>%
          select(
            SID:session, interrupt, beep_wpc, dec_time_c
            , lonely_mssd, lonely_wpc
            ) %>%
          mutate(moder = "none", mod_value_c = NA)
      )
  ) %>%
  left_join(
    # covariates 
    bl_demo_trim %>%
      select(
        SID, gender_gmc, age_c, edu_years_gmc, income_log_gmc
        , relstat_single_gmc, relstat_sep_gmc, dep_gmc
        )
  ) %>%
  crossing(
    RQ = c("RQ1", "RQ2")
    , cov = c("all", "none", "location", "dep")
    ) %>%
  drop_na(cog_value) %>%
  group_by(RQ, outcome, outcome_time, moder, cov, SID) %>%
  filter(n() >= 40) %>%
  group_by(RQ, outcome, outcome_time, moder, cov) %>%
  nest() %>%
  ungroup() %>% 
  filter(!(RQ == "RQ1" & (outcome_time == "prosp" | moder %in% c("ss_qual_wpc", "ss_quant_wpc"))) & 
         !(RQ == "RQ2" & moder %in% c("ss_qual_gmc", "ss_quant_gmc")))

# d <- (nested_models %>% filter(RQ == "RQ2" & moder == "ss_quant_wpc"))$data[[3]]
```

## Descriptives 

Now that the data are wrangled, we need to double check to make sure everything looks okay. To do so, we'll look at descriptive statistics, reliability of all scales, and zero-order correlations among study variables for both the EMA and Baseline data. 

### EMA 
#### Reliability 

First, for the EMA data (specifically loneliness and social interaction quality), we need to estimate the multilevel reliability to ensure that within- and between-person variability is systematic. Once estimated, we'll also go ahead and start wrangling that for use in a table combining all the descriptives. 

```{r}
ml_rel_fun <- function(x){
  y <- x %>%
    distinct() %>%
    pivot_wider(
      names_from = "item"
      , values_from = "value"
    ) %>% drop_na() %>% data.frame()
  multilevelTools::omegaSEM(
    data = y
    , id = "SID"
    , items = colnames(y)[5:7]
    , savemodel = TRUE
  )$Results
}

ema_sc_rel <- sc_soccog %>%
  select(
    SID, Date, session, interrupt
    , lonely_isolated, lonely_leftout, lonely_companion
    , ss_disclose, ss_understood, ss_rejected
    , medianRTc_nback = nback_medianRTc_pomp, medianRTc_vpa = vpa_medianRTc_pomp, medianRTc_dsm = dsm_medianRTc_pomp
    , score_vpa = vpa_score, score_nback = nback_score, score_dsm = dsm_score
    ) %>%
  filter(SID %in% subs) %>%
  pivot_longer(
    cols = c(-SID, -Date, -session, -interrupt)
    , names_to = c("variable", "item")
    , names_sep = "_"
    , values_to = "value"
  ) %>%
  group_by(SID, variable) %>% 
  mutate(sd = sd(value, na.rm = T)) %>%
  filter(sd != 0) %>%
  select(-sd) %>%
  group_by(variable) %>%
  nest() %>%
  ungroup() %>%
  mutate(rel = map(data, ml_rel_fun)) %>% 
  select(-data) %>%
  unnest(rel) %>%
  mutate(est = sprintf("%.2f<br>[%.2f, %.2f]", est, ci.lower, ci.upper)) %>%
  select(-ci.lower, -ci.upper) %>%
  pivot_wider(names_from = "label", values_from = "est")
```

#### Summary Statistics 

Next we need summary statistics of all EMA variables, including mean, sd, min, and max. We'll similarly restructure these to include in the table. 

```{r}
sc_ema_desc <- sc_soccog %>% 
  group_by(SID) %>%
  filter(n() >= 50) %>%
  select(
    SID, session, lonely, ss_quant = iso_when, ss_qual = ss
    , cog_comp, cog_medianRTc
    , interrupt, beep, dec_time
    ) %>%
  # mutate()
  pivot_longer(
    cols = c(-SID, -session)
    , names_to = "variable"
    , values_to = "value"
    , values_drop_na = T
  ) %>%
  group_by(SID, variable) %>%
  summarize(
    mean = mean(value)
    , sd = sd(value)
  ) %>%
  group_by(variable) %>%
  summarize(
    mean_mean = mean(mean)
    , sd_mean = sd(mean)
    , min_sd = min(sd)
    , max_sd = max(sd)
  ) %>%
  left_join(
    ema_sc_rel %>% 
      mutate(variable = mapvalues(variable, c("ss", "medianRTc", "score"), c("ss_qual", "cog_medianRTc", "cog_comp")))
    ) %>%
  mutate(variable = factor(variable, levels = var_labs$var, labels = var_labs$label)) %>%
  arrange(variable) %>%
  mutate(mean = sprintf("%.2f<br>(%.2f)", mean_mean, sd_mean)) %>%
  select(variable, mean, omega_within, omega_between)

varL <- tibble(vars = unique(sc_ema_desc$variable)) %>% mutate(n = 1:n(), num = paste(sprintf("%i. %s", n, vars)))

```

#### Zero-Order Correlations 

Lastly, we need our within-person zero-order correlations of all EMA variables (we'll do between-person ones along with the baseline data). Again, we'll wrangle these for table inclusion. 

```{r}
# make N = 1 correlation tables
cor_tab_fun <- function(r, SID){
  print(SID)
  r$r <- apply(r$r, c(1,2), function(x) sprintf("%.2f", x))
  r$r[which(r$p < .05, arr.ind = T)] <- 
    sprintf("<strong>%s</strong>" ,r$r[which(r$p < .05, arr.ind = T)])
  r$r[upper.tri(r$r, diag = F)] <- ""
  diag(r$r) <- "--"
  r <- r$r %>% data.frame %>%
    rownames_to_column("variable") %>%
    as_tibble() %>%
    mutate_all(as.character) %>%
    select(variable, everything()) %>%
    mutate(variable = factor(variable, levels = var_labs$var, labels = var_labs$label),
           variable = factor(variable, levels = varL$vars, labels = varL$num)) %>%
    arrange(variable) %>%
    select(variable, lonely, cog_comp, cog_medianRTc, ss_quant, ss_qual, beep, interrupt, dec_time) %>%
    setNames(c("variable", 1:8)) %>%
    kable(
    .
    , "html"
    , escape = F
    , col.names = c("EMA Variable", paste0(1:8, "."))
    , align = c("l", rep("c", 8))
    , caption = sprintf("<strong>Table SX</strong><br><em>Within-Person Correlations for Participant %s for all EMA variables</em>", SID)
  ) %>%
  kable_classic(html_font = "Times")
  save_kable(r, file = sprintf("03-results/04-tables/px-r-tabs/%s.html", SID))
  return(r)
}

# estimate and reshape correlations for between-person summaries
cor_fun <- function(x){
  r <- cor(x, use = "pairwise")
  r[upper.tri(r, diag = F)] <- NA
  fisherz(r) %>%
    data.frame() %>%
    rownames_to_column("V1") %>%
    pivot_longer(
      cols = -V1
      , names_to = "V2"
      , values_to = "z"
      , values_drop_na = T
      )
}

sc_ema_r <- sc_soccog %>% 
  group_by(SID) %>%
  filter(n() >= 50) %>%
  select(
    SID, lonely, cog_comp, cog_medianRTc 
    , ss_quant = iso_when, ss_qual = ss
    , beep, interrupt, dec_time
    ) %>%
  nest() %>%
  ungroup() %>%
  mutate(r_tab = map(data, ~corr.test(., use = "pairwise"))
         , r_tab = map2(r_tab, SID, cor_tab_fun)
         , r = map(data, cor_fun))

## reshape summaries for manuscript table
sc_ema_r <- sc_ema_r %>%
  select(-data, -r_tab) %>%
  unnest(r) %>%
  group_by(V1, V2) %>%
  summarize(
    sd = sd(z)
    , z = mean(z)
    , z = fisherz2r(z)
    , sd = fisherz2r(sd)
    ) %>%
  mutate(
    z = ifelse(is.nan(z), "--", ifelse(abs(z) < .01, sprintf("%.3f", z), sprintf("%.2f", z)))
    , sd = ifelse(is.nan(sd), "", sprintf("%.2f", sd))
    , z = ifelse(V1 != V2, sprintf("%s<br>(%s)", z, sd), "--")
    ) %>%
  select(-sd) %>%
  ungroup() %>%
  pivot_wider(
    names_from = "V2"
    , values_from = "z"
  ) %>%
  mutate(V1 = factor(V1, levels = var_labs$var, labels = var_labs$label),
         V1 = factor(V1, levels = varL$vars, labels = varL$num)) %>%
  arrange(V1) %>%
  select(V1, lonely, cog_comp, cog_medianRTc, ss_quant, ss_qual, beep, interrupt, dec_time) %>%
  setNames(c("variable", 1:8)) %>%
  left_join(
    sc_ema_desc %>% mutate(variable = factor(variable, levels = varL$vars, labels = varL$num))
    ) %>%
  select(variable, mean, omega_within, omega_between, everything())
```

#### Table 

Now that we have everything, let's make and save our table (Supplementary Table S18). 

```{r}
ema_desc_tab <- sc_ema_r %>%
  kable(
    .
    , "html"
    , escape = F
    , col.names = c("EMA Variable", "M (SD)", "$\\omega_w$ [CI]", "$\\omega_b$ [CI]", paste0(1:8, "."))
    , align = c("l", rep("c", 11))
    , caption = "<strong>Table S18</strong><br><em>Within-Person Descriptive Statistics, Correlations, and Reliability for all EMA variables</em>"
  ) %>%
  kable_classic(html_font = "Times") %>%
  add_header_above(c(" " = 1, "Within-Person Correlations [M (SD)]" = 8, "Descriptives" = 3))
ema_desc_tab
save_kable(ema_desc_tab, file = "03-results/04-tables/tabs18-wp-desc.html")
```

#### Cognitive Domains 

Anticipating questions around compositing cognitive domains, we now examined within-person associations among all cognitive domains to ensure that there is common variance. This will become Table S1. 

```{r}
cor_tab_fun <- function(r){
  r$r <- apply(r$r, c(1,2), function(x) sprintf("%.2f", x))
  r$r[which(r$p < .05, arr.ind = T)] <- 
    sprintf("<strong>%s</strong>" ,r$r[which(r$p < .05, arr.ind = T)])
  r$r[upper.tri(r$r, diag = F)] <- ""
  diag(r$r) <- "--"
  r <- r$r %>% data.frame %>%
    rownames_to_column("variable") %>%
    as_tibble() %>%
    mutate_all(as.character) %>%
    select(variable, everything()) 
  return(r)
}

cog_domains <- sc_soccog %>%
  group_by(SID) %>%
  summarize_at(vars(matches("cog_"), matches("dsm"), matches("vpa"), matches("nback"), -matches("pomp")), mean, na.rm = T)

cog_r_tab <- cog_domains %>% 
  pivot_longer(
    cols = -SID
    , values_to = "value"
    , names_to = "variable"
  ) %>%
  group_by(variable) %>%
  summarize_at(vars(value), ~sprintf("%.2f (%.2f)", mean(., na.rm = T), sd(.,na.rm = T))) %>%
  left_join(
    cog_domains %>%
      select(-SID) %>%
      corr.test() %>%
      cor_tab_fun()
  ) %>%
  setNames(c("variable", "M", 1:8)) %>%
  mutate(variable = factor(variable, var_labs$var, var_labs$label)) %>%
  arrange(variable) %>%
  mutate(variable = sprintf("%i. %s", 1:8, variable)) %>%
  kable( 
    .
    , "html"
    , escape = F
    , col.names = c("Cognitive Task", "M (SD)", paste0(1:8, "."))
    , align = c("l", rep("c", 9))
    , caption = "<strong>Table S1</strong><br><em>Between-Person Descriptive Statistics and Correlations of Cognitive Tasks</em>"
  ) %>%
  kable_classic(html_font = "Times") %>%
  add_header_above(c(" " = 1, " " = 1, "Correlations" = 8))
cog_r_tab
save_kable(cog_r_tab, file = "03-results/04-tables/tabs1-bp-cog-desc.html")
```



### Baseline 

Now, we repeat similar steps for the baseline data. 

#### Reliability

First, we need the scale reliability for loneliness, which we'll estimate and Omega. 

```{r}
lonely_omega <- bl_df %>% 
      select(SID, matches("loneliness")) %>%
      pivot_longer(
        cols = matches("loneliness")
        , names_to = "item"
        , values_to = "loneliness"
      ) %>%
      left_join(
        bl_cb %>% select(item = Item, Reverse)
      ) %>%
      mutate(loneliness = ifelse(Reverse == -1, 5 - loneliness, loneliness)) %>%
  select(-Reverse) %>%
  pivot_wider(names_from = "item", values_from = "loneliness", values_fn = mean) %>%
  select(-SID) %>%
  data.frame() %>%
  psych::omega()
lonely_omega$omega.tot
```

#### Summary Statistics 
Now, we need summary statistics, which includes counts and percentages for categorical variables and means and SDs for ordinal / continuous variables. 

```{r}
count_fun <- function(x) sprintf("%s (%.2f%%)", sum(x[x == 1], na.rm = T),sum(x[x == 1], na.rm = T)/length(x)*100)
subs <- sc_soccog %>% 
  select(SID) %>%
  group_by(SID) %>%
  filter(n() >= 50) %>% distinct() %>% pull(SID)
demo_tab <- bl_demo %>%
  filter(SID %in% subs) %>%
  mutate(gender_female = ifelse(gender == 1, 1, 0)) %>%
  select(SID, gender_female, relstat_part, relstat_sep, relstat_single,  ethnicity_hispanic = hispanic) %>%
  summarize_at(vars(-SID), count_fun) %>%
  pivot_longer(
    cols = everything()
    , names_to = "variable"
    , values_to = "n"
  ) %>%
  full_join(
    bl_demo %>%
      filter(SID %in% subs) %>%
      select(SID, age, edu_years, income, loneliness) %>%
      left_join(
        sc_soccog %>%
          select(SID, lonely_mssd, ss_quant, ss_qual) %>%
          distinct()
      )  %>%
      left_join(
        sc_soccog %>%
          group_by(SID) %>%
          summarize_at(vars(cog_comp, cog_medianRTc), mean, na.rm = T)
      ) %>%
      pivot_longer(
        cols = -SID
        , names_to = "variable"
        , values_to = "value"
      ) %>%
      group_by(variable) %>%
      summarize(value = sprintf("%.2f (%.2f)", mean(value, na.rm = T), sd(value, na.rm = T)))
  ) %>%
  full_join(
    bl_demo %>% 
      filter(SID %in% subs) %>%
      select(SID, race) %>%
      mutate(race = mapvalues(race, c("American Indian or Alaska Native", "Mixed Race"), rep("Other", 2))) %>%
      group_by(race) %>%
      tally() %>%
      mutate(n = sprintf("%i (%.2f%%)", n, n/sum(n)*100)) %>%
      rename(variable = race)
  ) %>%
  mutate(variable = factor(variable, levels = var_labs$var, labels = var_labs$label)) %>%
  arrange(variable)
```

#### Zero-Order Correlations 

And zero-order correlations among study variables. 

```{r}
bl_r <- bl_demo %>%
  filter(SID %in% subs) %>%
  select(SID, age, edu_years, income, loneliness, bl_cog) %>%
  left_join(
    sc_soccog %>%
      select(SID, lonely_mssd, ss_quant, ss_qual) %>%
      distinct()
  ) %>%
  left_join(
    sc_soccog %>%
      group_by(SID) %>%
      summarize_at(vars(cog_comp, cog_medianRTc), mean, na.rm = T)
  ) %>%
  select(loneliness, lonely_mssd, cog_comp, cog_medianRTc, ss_quant, ss_qual, age, edu_years, income) %>%
  corr.test(., use = "pairwise") 

cor_tab_fun <- function(r){
  r$r <- apply(r$r, c(1,2), function(x) sprintf("%.2f", x))
  r$r[which(r$p < .05, arr.ind = T)] <- 
    sprintf("<strong>%s</strong>" ,r$r[which(r$p < .05, arr.ind = T)])
  r$r[upper.tri(r$r, diag = F)] <- ""
  diag(r$r) <- "--"
  r <- r$r %>% data.frame %>%
    rownames_to_column("variable") %>%
    as_tibble() %>%
    mutate_all(as.character) %>%
    select(variable, everything()) 
  return(r)
}
```

#### Table 

And combine all of this into a table. 

```{r}
bl_r_tab <- cor_tab_fun(bl_r) %>%
  mutate(variable = factor(variable, levels = var_labs$var, labels = var_labs$label)) %>%
  arrange(variable) %>%
  setNames(c("variable", 1:9)) %>%
  left_join(demo_tab %>% select(-n)) %>%
  select(variable, value, everything()) %>%
  mutate(variable = sprintf("%i. %s", 1:n(), variable)) %>%
  kable( 
    .
    , "html"
    , escape = F
    , col.names = c("Baseline Variable", "M (SD)", paste0(1:9, "."))
    , align = c("l", rep("c", 10))
    , caption = "<strong>Table 3</strong><br><em>Between-Person Descriptive Statistics and Correlations</em>"
  ) %>%
  kable_classic(html_font = "Times") %>%
  add_header_above(c(" " = 1, " " = 1, "Correlations" = 9))
bl_r_tab
save_kable(bl_r_tab, file = "03-results/04-tables/tab3-bp-desc.html")
```

## Attrition Analyses 

Lastly, we conduct attrition analyses to test whether those participants with enough EMA to meet inclusion differed from those who did not on the basis of: 

- Years of education 
- Loneliness 
- Gender 
- Age 
- Income 
- Baseline cognitive function 
- Race 
- Ethnicity 
- Relationship Status


```{r}
sc_all %>%
  filter(SID %in% subs) %>%
  group_by(SID) %>%
  tally() %>%
  summarize_at(vars(n), lst(mean, median,sd,min, max))
bl_demo

sc_all %>% 
  group_by(SID) %>% 
  tally() %>%
  filter(n >= 5) %>%
  summarize_at(vars(n), lst(mean, median,sd,min, max))

sc_dropped <- sc_all %>% 
  group_by(SID) %>% 
  tally() %>%
  filter(n >= 5 & n < 50) %>%
  arrange(desc(n)) 

sc_dropped %>%
  summarize_at(vars(n), funs(mean, sd, min, max, median))

orig_subs <- sc_all %>% 
  group_by(SID) %>% 
  tally() %>%
  filter(n >= 5) %>%
  arrange(desc(n)) 

bl_demo %>% 
  right_join(orig_subs) %>%
  select(SID, edu_years, n, loneliness, age, income_log)  %>%
  pivot_longer(
    cols = -SID
    , names_to = "var"
    , values_to = "value"
    ) %>%
  group_by(var) %>%
  summarize_at(vars(value), lst(mean, sd), na.rm = T)

bl_demo %>% 
  filter(SID %in% subs) %>%
  select(SID, edu_years, loneliness, age, income_log)  %>%
  pivot_longer(
    cols = -SID
    , names_to = "var"
    , values_to = "value"
    ) %>%
  group_by(var) %>%
  summarize_at(vars(value), lst(mean, sd), na.rm = T)

bl_demo %>% 
  filter(SID %in% subs) %>%
  group_by(race) %>% 
  tally() %>%
  mutate(perc = n / sum(n)*100)

bl_demo %>% 
  right_join(orig_subs) %>% 
  group_by(race) %>% 
  tally() %>%
  mutate(perc = n / sum(n)*100)

bl_demo %>% 
  filter(SID %in% subs) %>%
  group_by(gender) %>% 
  tally() %>%
  mutate(perc = n / sum(n)*100)

bl_demo %>% 
  right_join(orig_subs) %>% 
  group_by(gender) %>% 
  tally() %>%
  mutate(perc = n / sum(n)*100)
```


```{r}
tab_t_att <- bl_demo %>% 
  # left_join(
  #   sc_all %>%
  #     group_by(SID) %>%
  #     summarize_at(vars(cog_comp, cog_medianRTc), mean, na.rm = T) %>%
  #     ungroup()
  # ) %>%
  right_join(orig_subs) %>%
  select(SID, edu_years, n, loneliness, bl_cog, age, income_log) %>%
  mutate(group = factor(ifelse(n >= 50, "final", "dropped"), levels = c("final", "dropped"))) %>%
  pivot_longer(
    cols = c(-SID, -group, -n)
    , names_to = "var"
    , values_to = "value"
  ) %>%
  group_by(var) %>%
  nest() %>%
  ungroup() %>%
  mutate(t = map(data, ~tidy(t.test(value~group, data = .)))) %>%
  unnest(t) %>%
  mutate(sig = ifelse(p.value < .05, "sig", "ns")) %>%
  mutate_at(vars(estimate:conf.high), ~ifelse(sig == "sig", sprintf("<strong>%.2f</strong>",.), round(.,2))) %>%
  # filter(term == "groupdropped") %>%
  select(var, estimate:conf.high) %>%
  kable(
    .
    , "html"
    , digits = 2
    , caption = "<strong>Table S16</strong><br><em>Attrition Analyses for Continuous Variables</em>"
    , escape = F
  ) %>%
  kable_classic(full_width = F, html_font = "Times") %>%
  footnote("Group differences were estimated using $t$-tests.", escape = F)
tab_t_att
save_kable(tab_t_att, file = "03-results/04-tables/tabs16-att-t.html")

chisq_fun <- function(x){
  tidy(chisq.test(table(x$group, x$value)))
}

tab_chi_att <- bl_demo %>% 
  right_join(orig_subs) %>%
  select(SID, n, race, gender, hispanic, demo_relationship) %>%
  mutate(group = factor(ifelse(n >= 50, "final", "dropped"), levels = c("final", "dropped"))) %>%
  mutate_at(vars(gender:demo_relationship), as.character) %>%
  pivot_longer(
    cols = c(-SID, -group, -n)
    , names_to = "var"
    , values_to = "value"
  ) %>%
  group_by(var) %>%
  nest() %>%
  ungroup() %>%
  mutate(chi = map(data, chisq_fun)) %>%
  unnest(chi) %>%
  mutate(sig = ifelse(p.value < .05, "sig", "ns")) %>%
  mutate_at(vars(statistic, p.value), ~ifelse(sig == "sig", sprintf("<strong>%.2f</strong>",.), round(.,2))) %>%
  select(-data, -method, -sig) %>%
  kable(
    .
    , "html"
    , digits = 2
    , escape = F
    , caption = "<strong>Table S17</strong><br><em>Attrition Analyses for Categorical Variables</em>"
  ) %>%
  kable_classic(full_width = F, html_font = "Times") %>%
  footnote("Group differences were estimated using $\\chi^2$ tests.", escape = F)
tab_chi_att
save_kable(tab_chi_att, file = "03-results/04-tables/tabs17-att-chi.html")
```




